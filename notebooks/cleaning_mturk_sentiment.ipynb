{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0      89\n",
      "1     326\n",
      "2    2722\n",
      "3     981\n",
      "4     181\n",
      "Name: text, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGAPORE - A popular burger chain from Ameri...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"(In some cases) the wife had to be taken to t...</td>\n",
       "      <td>Very Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"(Kon Chun) was a very good guy and everyone i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\", see what happens if you give an honest answer.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"A cat cafe might not be the best place for a ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_label  \\\n",
       "0   SINGAPORE - A popular burger chain from Ameri...   Very Positive   \n",
       "1  \"(In some cases) the wife had to be taken to t...   Very Negative   \n",
       "2  \"(Kon Chun) was a very good guy and everyone i...        Positive   \n",
       "3  \", see what happens if you give an honest answer.         Neutral   \n",
       "4  \"A cat cafe might not be the best place for a ...        Positive   \n",
       "\n",
       "   sentiment_score  \n",
       "0                4  \n",
       "1                0  \n",
       "2                3  \n",
       "3                2  \n",
       "4                3  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"290420_Mturk_sentences_agreed.csv\")\n",
    "print(data.groupby('sentiment_score')['text'].count())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4299"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 text  sentiment  agreement\n",
      "sentiment_score                            \n",
      "0                 167        167        167\n",
      "1                 210        210        210\n",
      "2                 549        549        549\n",
      "3                 401        401        401\n",
      "4                 332        332        332\n"
     ]
    }
   ],
   "source": [
    "data_ = pd.read_csv(\"290420_Mturk_sentences_NOT_agreed.csv\")\n",
    "print(data_.groupby('sentiment_score').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text      sentiment  \\\n",
      "0  Come the weekends, families, couples and frien...       Positive   \n",
      "1  Come the weekends, families, couples and frien...        Neutral   \n",
      "2  Come the weekends, families, couples and frien...  Very Positive   \n",
      "3  It was also very easy for me to feel.. that th...  Very Negative   \n",
      "4  It was also very easy for me to feel.. that th...       Negative   \n",
      "\n",
      "   sentiment_score  agreement  \n",
      "0                4          2  \n",
      "1                2          2  \n",
      "2                4          2  \n",
      "3                0          2  \n",
      "4                0          2  \n"
     ]
    }
   ],
   "source": [
    "def get_nss(x):\n",
    "    if x==\"Positive\":\n",
    "        return 4\n",
    "    elif x==\"Neutral\":\n",
    "        return 2\n",
    "    elif x==\"Negative\":\n",
    "        return 0\n",
    "    elif x==\"Very Positive\":\n",
    "        return 4\n",
    "    elif x==\"Very Negative\":\n",
    "        return 0\n",
    "    else: return None\n",
    "\n",
    "del data_['agreement']\n",
    "data_[\"sentiment_score\"]=data_['sentiment'].apply(lambda x: get_nss(str(x)))\n",
    "gdata = data_.groupby(['text'])['sentiment_score'].nunique().reset_index(name=\"agreement\")\n",
    "\n",
    "ndata = pd.merge(data_,gdata,on=['text'])\n",
    "ndata_ = ndata[ndata['agreement'] < 3]\n",
    "ndata__ = ndata[ndata.agreement >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndata_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndata__.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>agreement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Come the weekends, families, couples and frien...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come the weekends, families, couples and frien...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Come the weekends, families, couples and frien...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was also very easy for me to feel.. that th...</td>\n",
       "      <td>Very Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was also very easy for me to feel.. that th...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It was also very easy for me to feel.. that th...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mrs Sng Ngoi May, the executive director of Pa...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mrs Sng Ngoi May, the executive director of Pa...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mrs Sng Ngoi May, the executive director of Pa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Oh, how I laughed at that.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Oh, how I laughed at that.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, how I laughed at that.</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mcdonald's, a popular studying spot for studen...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>She feels it's real love,\" adds Lee, who is in...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She feels it's real love,\" adds Lee, who is in...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text      sentiment  \\\n",
       "0   Come the weekends, families, couples and frien...       Positive   \n",
       "1   Come the weekends, families, couples and frien...        Neutral   \n",
       "2   Come the weekends, families, couples and frien...  Very Positive   \n",
       "3   It was also very easy for me to feel.. that th...  Very Negative   \n",
       "4   It was also very easy for me to feel.. that th...       Negative   \n",
       "5   It was also very easy for me to feel.. that th...        Neutral   \n",
       "6   Mrs Sng Ngoi May, the executive director of Pa...        Neutral   \n",
       "7   Mrs Sng Ngoi May, the executive director of Pa...  Very Positive   \n",
       "8   Mrs Sng Ngoi May, the executive director of Pa...       Positive   \n",
       "12                         Oh, how I laughed at that.       Positive   \n",
       "13                         Oh, how I laughed at that.        Neutral   \n",
       "14                         Oh, how I laughed at that.  Very Positive   \n",
       "15  Mcdonald's, a popular studying spot for studen...        Neutral   \n",
       "16  Mcdonald's, a popular studying spot for studen...       Positive   \n",
       "17  Mcdonald's, a popular studying spot for studen...       Positive   \n",
       "18  Mcdonald's, a popular studying spot for studen...       Positive   \n",
       "19  Mcdonald's, a popular studying spot for studen...  Very Positive   \n",
       "20  Mcdonald's, a popular studying spot for studen...        Neutral   \n",
       "21  She feels it's real love,\" adds Lee, who is in...        Neutral   \n",
       "22  She feels it's real love,\" adds Lee, who is in...  Very Positive   \n",
       "\n",
       "    sentiment_score  agreement  \n",
       "0                 4          2  \n",
       "1                 2          2  \n",
       "2                 4          2  \n",
       "3                 0          2  \n",
       "4                 0          2  \n",
       "5                 2          2  \n",
       "6                 2          2  \n",
       "7                 4          2  \n",
       "8                 4          2  \n",
       "12                4          2  \n",
       "13                2          2  \n",
       "14                4          2  \n",
       "15                2          2  \n",
       "16                4          2  \n",
       "17                4          2  \n",
       "18                4          2  \n",
       "19                4          2  \n",
       "20                2          2  \n",
       "21                2          2  \n",
       "22                4          2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata_.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gndata_ = ndata_.groupby('text')\n",
    "\n",
    "for text,grp in gndata_:\n",
    "    lst = grp['sentiment_score'].tolist()\n",
    "    data = data.append({'text':text, 'sentiment_score':max(set(lst), key=lst.count)}, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4768"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0     240\n",
      "1     326\n",
      "2    2726\n",
      "3     981\n",
      "4     495\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('sentiment_score')['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndata__.drop_duplicates('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NAS/home01/toshal/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "data2 = data[data.sentiment_score == 2]\n",
    "data2 = data2.append(ndata__.drop_duplicates('text'),ignore_index=True)\n",
    "data2.to_csv(\"290420_neutral_sentences_nonagreed.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agreement</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>\", see what happens if you give an honest answer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A leader is best when people barely know he e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A lot of good engineers end up selling proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>\"A performance in the UK is very spontaneous a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>\"About 20 to 30 per cent of our clientele requ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agreement sentiment sentiment_label  sentiment_score  \\\n",
       "0        NaN       NaN         Neutral                2   \n",
       "1        NaN       NaN         Neutral                2   \n",
       "2        NaN       NaN         Neutral                2   \n",
       "3        NaN       NaN         Neutral                2   \n",
       "4        NaN       NaN         Neutral                2   \n",
       "\n",
       "                                                text  \n",
       "0  \", see what happens if you give an honest answer.  \n",
       "1  \"A leader is best when people barely know he e...  \n",
       "2  \"A lot of good engineers end up selling proper...  \n",
       "3  \"A performance in the UK is very spontaneous a...  \n",
       "4  \"About 20 to 30 per cent of our clientele requ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2790"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make all 1 -> 0, 3 -> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0     240\n",
      "1     326\n",
      "2    2726\n",
      "3     981\n",
      "4     495\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('sentiment_score')['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ss(s):\n",
    "    if s == 1:\n",
    "        return 0\n",
    "    elif s == 3:\n",
    "        return 4\n",
    "    else: \n",
    "        return s\n",
    "    \n",
    "data['sentiment_score'] = data['sentiment_score'].apply(lambda x: replace_ss(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0     566\n",
      "2    2726\n",
      "4    1476\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('sentiment_score')['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGAPORE - A popular burger chain from Ameri...</td>\n",
       "      <td>Very Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"(In some cases) the wife had to be taken to t...</td>\n",
       "      <td>Very Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"(Kon Chun) was a very good guy and everyone i...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"A cat cafe might not be the best place for a ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"About 3,000 government offials will try their...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_label  \\\n",
       "0   SINGAPORE - A popular burger chain from Ameri...   Very Positive   \n",
       "1  \"(In some cases) the wife had to be taken to t...   Very Negative   \n",
       "2  \"(Kon Chun) was a very good guy and everyone i...        Positive   \n",
       "4  \"A cat cafe might not be the best place for a ...        Positive   \n",
       "9  \"About 3,000 government offials will try their...        Positive   \n",
       "\n",
       "   sentiment_score  \n",
       "0                4  \n",
       "1                0  \n",
       "2                4  \n",
       "4                4  \n",
       "9                4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data[data['sentiment_score'] != 2]\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final phrases and sentences before PTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NAS/home01/toshal/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers arriving by boat</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  #words  \\\n",
       "0           0  Under Canberra's immigration policy, asylum-se...    28.0   \n",
       "1           0                     Canberra 's immigration policy     4.0   \n",
       "2           0                                        Canberra 's     2.0   \n",
       "3           0                    asylum-seekers arriving by boat     4.0   \n",
       "4           0                                     asylum-seekers     1.0   \n",
       "\n",
       "  phrase_id  score_correct is_sent  snlp_sentiment_score  \n",
       "0      0-p1            2.0    True                   NaN  \n",
       "1      0-p2            2.0     NaN                   2.0  \n",
       "2      0-p3            2.0     NaN                   2.0  \n",
       "3      0-p4            2.0     NaN                   2.0  \n",
       "4      0-p5            2.0     NaN                   2.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"250420_phrases_sentiment.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13240"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['is_sent']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469759"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['snlp_sentiment_score']!= None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469759"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers arriving by boat</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>boat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>the centres for processing</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the centres</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>processing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>their asylum application</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0-p10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>they</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>arriving by boat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0-p13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>are transferred to the centres for processing</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0-p14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>transferred to the centres for processing</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0-p15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>is successful</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>are permanently resettled outside Australia .</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0-p17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>resettled outside Australia .</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>Under</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra's</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>immigration</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>policy,</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>arriving</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p24</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>by</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>boat</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>are</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>transferred</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>says..</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-p25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>Five large high-volume, low-speed fans will co...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>Five large high-volume , low-speed fans</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2-p2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>their hair</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2-p4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>saving energy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2-p5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>will cool diners without messing up their hair</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2-p6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2</td>\n",
       "      <td>cool diners without messing up their hair</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2-p7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>messing up their hair</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2-p8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>Five</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>large</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>high-volume,</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2</td>\n",
       "      <td>low-speed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>fans</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2</td>\n",
       "      <td>will</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>cool</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>without</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>messing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>up</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>their</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>hair,</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>while</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>also</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>saving</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>energy..</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2-p25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>Market players say it could take months for lo...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3-p1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>Market players</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3-p2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>it</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3-p3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>months for long-term investors</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3-p4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id                                               text  #words  \\\n",
       "0            0  Under Canberra's immigration policy, asylum-se...    28.0   \n",
       "1            0                     Canberra 's immigration policy     4.0   \n",
       "2            0                                        Canberra 's     2.0   \n",
       "3            0                    asylum-seekers arriving by boat     4.0   \n",
       "4            0                                     asylum-seekers     1.0   \n",
       "5            0                                               boat     1.0   \n",
       "6            0                         the centres for processing     4.0   \n",
       "7            0                                        the centres     2.0   \n",
       "8            0                                         processing     1.0   \n",
       "9            0                           their asylum application     3.0   \n",
       "10           0                                               they     1.0   \n",
       "11           0                                          Australia     1.0   \n",
       "12           0                                   arriving by boat     3.0   \n",
       "13           0      are transferred to the centres for processing     7.0   \n",
       "14           0          transferred to the centres for processing     6.0   \n",
       "15           0                                      is successful     2.0   \n",
       "16           0      are permanently resettled outside Australia .     6.0   \n",
       "17           0                      resettled outside Australia .     4.0   \n",
       "18           0                                              Under     1.0   \n",
       "19           0                                         Canberra's     1.0   \n",
       "20           0                                        immigration     1.0   \n",
       "21           0                                            policy,     1.0   \n",
       "22           0                                     asylum-seekers     1.0   \n",
       "23           0                                           arriving     1.0   \n",
       "24           0                                                 by     1.0   \n",
       "25           0                                               boat     1.0   \n",
       "26           0                                                are     1.0   \n",
       "27           0                                        transferred     1.0   \n",
       "28           0                                                 to     1.0   \n",
       "29           0                                                the     1.0   \n",
       "..         ...                                                ...     ...   \n",
       "70           1                                             says..     1.0   \n",
       "71           2  Five large high-volume, low-speed fans will co...    17.0   \n",
       "72           2            Five large high-volume , low-speed fans     6.0   \n",
       "73           2                                             diners     1.0   \n",
       "74           2                                         their hair     2.0   \n",
       "75           2                                      saving energy     2.0   \n",
       "76           2     will cool diners without messing up their hair     8.0   \n",
       "77           2          cool diners without messing up their hair     7.0   \n",
       "78           2                              messing up their hair     4.0   \n",
       "79           2                                               Five     1.0   \n",
       "80           2                                              large     1.0   \n",
       "81           2                                       high-volume,     1.0   \n",
       "82           2                                          low-speed     1.0   \n",
       "83           2                                               fans     1.0   \n",
       "84           2                                               will     1.0   \n",
       "85           2                                               cool     1.0   \n",
       "86           2                                             diners     1.0   \n",
       "87           2                                            without     1.0   \n",
       "88           2                                            messing     1.0   \n",
       "89           2                                                 up     1.0   \n",
       "90           2                                              their     1.0   \n",
       "91           2                                              hair,     1.0   \n",
       "92           2                                              while     1.0   \n",
       "93           2                                               also     1.0   \n",
       "94           2                                             saving     1.0   \n",
       "95           2                                           energy..     1.0   \n",
       "96           3  Market players say it could take months for lo...    25.0   \n",
       "97           3                                     Market players     2.0   \n",
       "98           3                                                 it     1.0   \n",
       "99           3                     months for long-term investors     4.0   \n",
       "\n",
       "   phrase_id  score_correct is_sent  snlp_sentiment_score  \n",
       "0       0-p1            2.0    True                   NaN  \n",
       "1       0-p2            2.0     NaN                   2.0  \n",
       "2       0-p3            2.0     NaN                   2.0  \n",
       "3       0-p4            2.0     NaN                   2.0  \n",
       "4       0-p5            2.0     NaN                   2.0  \n",
       "5       0-p6            2.0     NaN                   2.0  \n",
       "6       0-p7            2.0     NaN                   2.0  \n",
       "7       0-p8            2.0     NaN                   2.0  \n",
       "8       0-p9            2.0     NaN                   2.0  \n",
       "9      0-p10            2.0     NaN                   2.0  \n",
       "10     0-p11            2.0     NaN                   2.0  \n",
       "11     0-p12            2.0     NaN                   2.0  \n",
       "12     0-p13            2.0     NaN                   2.0  \n",
       "13     0-p14            2.0     NaN                   2.0  \n",
       "14     0-p15            2.0     NaN                   2.0  \n",
       "15     0-p16            2.0     NaN                   3.0  \n",
       "16     0-p17            2.0     NaN                   2.0  \n",
       "17     0-p18            2.0     NaN                   2.0  \n",
       "18     0-p19            2.0     NaN                   2.0  \n",
       "19     0-p20            2.0     NaN                   2.0  \n",
       "20     0-p21            2.0     NaN                   2.0  \n",
       "21     0-p22            2.0     NaN                   2.0  \n",
       "22     0-p23            2.0     NaN                   2.0  \n",
       "23     0-p24            2.0     NaN                   2.0  \n",
       "24     0-p25            2.0     NaN                   2.0  \n",
       "25     0-p26            2.0     NaN                   2.0  \n",
       "26     0-p27            2.0     NaN                   2.0  \n",
       "27     0-p28            2.0     NaN                   2.0  \n",
       "28     0-p29            2.0     NaN                   2.0  \n",
       "29     0-p30            2.0     NaN                   2.0  \n",
       "..       ...            ...     ...                   ...  \n",
       "70     1-p25            1.0     NaN                   2.0  \n",
       "71      2-p1            3.0    True                   NaN  \n",
       "72      2-p2            3.0     NaN                   1.0  \n",
       "73      2-p3            3.0     NaN                   2.0  \n",
       "74      2-p4            3.0     NaN                   2.0  \n",
       "75      2-p5            3.0     NaN                   2.0  \n",
       "76      2-p6            3.0     NaN                   2.0  \n",
       "77      2-p7            3.0     NaN                   2.0  \n",
       "78      2-p8            3.0     NaN                   2.0  \n",
       "79      2-p9            3.0     NaN                   2.0  \n",
       "80     2-p10            3.0     NaN                   2.0  \n",
       "81     2-p11            3.0     NaN                   2.0  \n",
       "82     2-p12            3.0     NaN                   2.0  \n",
       "83     2-p13            3.0     NaN                   3.0  \n",
       "84     2-p14            3.0     NaN                   2.0  \n",
       "85     2-p15            3.0     NaN                   3.0  \n",
       "86     2-p16            3.0     NaN                   2.0  \n",
       "87     2-p17            3.0     NaN                   2.0  \n",
       "88     2-p18            3.0     NaN                   1.0  \n",
       "89     2-p19            3.0     NaN                   2.0  \n",
       "90     2-p20            3.0     NaN                   2.0  \n",
       "91     2-p21            3.0     NaN                   2.0  \n",
       "92     2-p22            3.0     NaN                   2.0  \n",
       "93     2-p23            3.0     NaN                   2.0  \n",
       "94     2-p24            3.0     NaN                   3.0  \n",
       "95     2-p25            3.0     NaN                   2.0  \n",
       "96      3-p1            1.0    True                   NaN  \n",
       "97      3-p2            1.0     NaN                   2.0  \n",
       "98      3-p3            1.0     NaN                   2.0  \n",
       "99      3-p4            1.0     NaN                   2.0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2791\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\", see what happens if you give an honest answer.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A leader is best when people barely know he e...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"A lot of good engineers end up selling proper...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"A performance in the UK is very spontaneous a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"About 20 to 30 per cent of our clientele requ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  new_score\n",
       "0  \", see what happens if you give an honest answer.        3.0\n",
       "1  \"A leader is best when people barely know he e...        4.0\n",
       "2  \"A lot of good engineers end up selling proper...        0.0\n",
       "3  \"A performance in the UK is very spontaneous a...        0.0\n",
       "4  \"About 20 to 30 per cent of our clientele requ...        0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new = pd.read_csv(\"290420_neutral_sentences_nonagreed_cleanss.csv\")\n",
    "print(len(data_new.index))\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.columns = ['text','sentiment_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat([data_final[['text','sentiment_score']],data_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0.0    1425\n",
      "1.0     109\n",
      "2.0     654\n",
      "3.0     673\n",
      "4.0    1949\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_final.groupby('sentiment_score')['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469759\n",
      "4833\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index))\n",
    "print(len(data_final.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4810\n"
     ]
    }
   ],
   "source": [
    "data_final = data_final.dropna()\n",
    "print(len(data_final.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sen = pd.read_csv(\"250420_sentences_Mturk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>score_g</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>223692-s52</td>\n",
       "      <td>Do you know of any good and cheap hawker fare?</td>\n",
       "      <td>you|any good and cheap hawker fare|know of any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>189729-s24</td>\n",
       "      <td>Living molecules bear a charge and thus can in...</td>\n",
       "      <td>Living molecules|a charge|others of their kind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153882-s30</td>\n",
       "      <td>In the stills, Chow is captioned as saying: \"T...</td>\n",
       "      <td>the stills|Chow|They|a perfect match , a match...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146531-s12</td>\n",
       "      <td>The good news is, I don't plan to purge my she...</td>\n",
       "      <td>The good news|I|my shelves of his books|my she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>208594-s8</td>\n",
       "      <td>So for the lyrics, I suggested, 'Let us the pe...</td>\n",
       "      <td>the lyrics|I|us|the people of Singapore progre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  score_correct  score_g sentence_id  \\\n",
       "0    4.0            NaN      4.0  223692-s52   \n",
       "1    4.0            NaN      4.0  189729-s24   \n",
       "2    4.0            NaN      4.0  153882-s30   \n",
       "3    4.0            NaN      4.0  146531-s12   \n",
       "4    4.0            NaN      4.0   208594-s8   \n",
       "\n",
       "                                                text  \\\n",
       "0     Do you know of any good and cheap hawker fare?   \n",
       "1  Living molecules bear a charge and thus can in...   \n",
       "2  In the stills, Chow is captioned as saying: \"T...   \n",
       "3  The good news is, I don't plan to purge my she...   \n",
       "4  So for the lyrics, I suggested, 'Let us the pe...   \n",
       "\n",
       "                                             phrases  \n",
       "0  you|any good and cheap hawker fare|know of any...  \n",
       "1  Living molecules|a charge|others of their kind...  \n",
       "2  the stills|Chow|They|a perfect match , a match...  \n",
       "3  The good news|I|my shelves of his books|my she...  \n",
       "4  the lyrics|I|us|the people of Singapore progre...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sen = data_sen[['sentence_id','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4888\n"
     ]
    }
   ],
   "source": [
    "print(len(data_sen.index))\n",
    "data_sen_f = pd.merge(data_sen,data_final,how='outer', on='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4924"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_sen_f.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223692-s52</td>\n",
       "      <td>Do you know of any good and cheap hawker fare?</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189729-s24</td>\n",
       "      <td>Living molecules bear a charge and thus can in...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153882-s30</td>\n",
       "      <td>In the stills, Chow is captioned as saying: \"T...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146531-s12</td>\n",
       "      <td>The good news is, I don't plan to purge my she...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>208594-s8</td>\n",
       "      <td>So for the lyrics, I suggested, 'Let us the pe...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  \\\n",
       "0  223692-s52     Do you know of any good and cheap hawker fare?   \n",
       "1  189729-s24  Living molecules bear a charge and thus can in...   \n",
       "2  153882-s30  In the stills, Chow is captioned as saying: \"T...   \n",
       "3  146531-s12  The good news is, I don't plan to purge my she...   \n",
       "4   208594-s8  So for the lyrics, I suggested, 'Let us the pe...   \n",
       "\n",
       "   sentiment_score  \n",
       "0              3.0  \n",
       "1              2.0  \n",
       "2              4.0  \n",
       "3              4.0  \n",
       "4              4.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sen_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sen_f.to_csv(\"110520_final_merged_sentences.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_sen = pd.read_csv(\"110520_final_merged_sentences_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92220-s8</td>\n",
       "      <td>Newcastle manager Alan Pardew's touchline ant...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147270-s27</td>\n",
       "      <td>SINGAPORE - A popular burger chain from Ameri...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152175-s2</td>\n",
       "      <td>- a caper so goofy it just has to work.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218823-s53</td>\n",
       "      <td>- Enjoying the view at The Lantern Bar This sw...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235816-s18</td>\n",
       "      <td>- Left-back Benedikt Howedes had Germany's bes...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  \\\n",
       "0    92220-s8   Newcastle manager Alan Pardew's touchline ant...   \n",
       "1  147270-s27   SINGAPORE - A popular burger chain from Ameri...   \n",
       "2   152175-s2            - a caper so goofy it just has to work.   \n",
       "3  218823-s53  - Enjoying the view at The Lantern Bar This sw...   \n",
       "4  235816-s18  - Left-back Benedikt Howedes had Germany's bes...   \n",
       "\n",
       "   sentiment_score  \n",
       "0              0.0  \n",
       "1              4.0  \n",
       "2              4.0  \n",
       "3              4.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_score\n",
      "0.0    1438\n",
      "1.0     114\n",
      "2.0     669\n",
      "3.0     690\n",
      "4.0    1975\n",
      "Name: text, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_final_sen.groupby('sentiment_score')['text'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4889"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_final_sen.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine with old sentences and phrases sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NAS/home01/toshal/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"250420_phrases_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers arriving by boat</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  #words  \\\n",
       "0           0  Under Canberra's immigration policy, asylum-se...    28.0   \n",
       "1           0                     Canberra 's immigration policy     4.0   \n",
       "2           0                                        Canberra 's     2.0   \n",
       "3           0                    asylum-seekers arriving by boat     4.0   \n",
       "4           0                                     asylum-seekers     1.0   \n",
       "\n",
       "  phrase_id  score_correct is_sent  snlp_sentiment_score  \n",
       "0      0-p1            2.0    True                   NaN  \n",
       "1      0-p2            2.0     NaN                   2.0  \n",
       "2      0-p3            2.0     NaN                   2.0  \n",
       "3      0-p4            2.0     NaN                   2.0  \n",
       "4      0-p5            2.0     NaN                   2.0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_sen['phrase_id'] = data_final_sen['sentence_id'] + '-p1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>phrase_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92220-s8</td>\n",
       "      <td>Newcastle manager Alan Pardew's touchline ant...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92220-s8-p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147270-s27</td>\n",
       "      <td>SINGAPORE - A popular burger chain from Ameri...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>147270-s27-p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152175-s2</td>\n",
       "      <td>- a caper so goofy it just has to work.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>152175-s2-p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218823-s53</td>\n",
       "      <td>- Enjoying the view at The Lantern Bar This sw...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>218823-s53-p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235816-s18</td>\n",
       "      <td>- Left-back Benedikt Howedes had Germany's bes...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235816-s18-p1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  \\\n",
       "0    92220-s8   Newcastle manager Alan Pardew's touchline ant...   \n",
       "1  147270-s27   SINGAPORE - A popular burger chain from Ameri...   \n",
       "2   152175-s2            - a caper so goofy it just has to work.   \n",
       "3  218823-s53  - Enjoying the view at The Lantern Bar This sw...   \n",
       "4  235816-s18  - Left-back Benedikt Howedes had Germany's bes...   \n",
       "\n",
       "   sentiment_score      phrase_id  \n",
       "0              0.0    92220-s8-p1  \n",
       "1              4.0  147270-s27-p1  \n",
       "2              4.0   152175-s2-p1  \n",
       "3              4.0  218823-s53-p1  \n",
       "4              0.0  235816-s18-p1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final_sen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469761\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-p3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers arriving by boat</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0-p4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-p5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text  #words  \\\n",
       "0           0  Under Canberra's immigration policy, asylum-se...    28.0   \n",
       "1           0                     Canberra 's immigration policy     4.0   \n",
       "2           0                                        Canberra 's     2.0   \n",
       "3           0                    asylum-seekers arriving by boat     4.0   \n",
       "4           0                                     asylum-seekers     1.0   \n",
       "\n",
       "  phrase_id  score_correct is_sent  snlp_sentiment_score  sentiment_score  \n",
       "0      0-p1            2.0    True                   NaN              NaN  \n",
       "1      0-p2            2.0     NaN                   2.0              NaN  \n",
       "2      0-p3            2.0     NaN                   2.0              NaN  \n",
       "3      0-p4            2.0     NaN                   2.0              NaN  \n",
       "4      0-p5            2.0     NaN                   2.0              NaN  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = pd.merge(df,data_final_sen[['sentiment_score','phrase_id']],on=['phrase_id'],how='outer')\n",
    "print(len(data_clean.index))\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469759\n"
     ]
    }
   ],
   "source": [
    "data_clean = data_clean.dropna(subset=['phrase_id'])\n",
    "print(len(data_clean.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentence_id                                               text #words  \\\n",
      "0           0  Under Canberra's immigration policy, asylum-se...     28   \n",
      "1           0                     Canberra 's immigration policy      4   \n",
      "2           0                                        Canberra 's      2   \n",
      "3           0                    asylum-seekers arriving by boat      4   \n",
      "4           0                                     asylum-seekers      1   \n",
      "\n",
      "  phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "0      0-p1            2.0    True                 None            None  \n",
      "1      0-p2            2.0    None                    2            None  \n",
      "2      0-p3            2.0    None                    2            None  \n",
      "3      0-p4            2.0    None                    2            None  \n",
      "4      0-p5            2.0    None                    2            None  \n"
     ]
    }
   ],
   "source": [
    "def senti_sc(s):\n",
    "    if s.phrase_id.endswith('-p1'):\n",
    "        if s.sentiment_score == 'None':\n",
    "            s.sentiment_score = s.score_correct\n",
    "    else:\n",
    "        s.sentiment_score = s.snlp_sentiment_score\n",
    "    return s\n",
    "            \n",
    "data_clean = data_clean.astype(object).replace(np.nan, 'None')\n",
    "print(data_clean.head())\n",
    "data_clean = data_clean.apply(lambda row : senti_sc(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468759</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>daring one-armed lifts</td>\n",
       "      <td>3</td>\n",
       "      <td>156630-s2-p10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468760</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>is no room for dramatic momentum amidst all th...</td>\n",
       "      <td>18</td>\n",
       "      <td>156630-s2-p11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468761</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>There</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468762</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468763</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468764</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>room</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468765</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468766</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>dramatic</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468767</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>momentum</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468768</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>amidst</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468769</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468770</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468771</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>dizzying</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468772</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>pirouettes,</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468773</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>high-flying</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468774</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>jumps</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468775</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468776</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>daring</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468777</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>one-armed</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468778</th>\n",
       "      <td>156630-s2</td>\n",
       "      <td>lifts.</td>\n",
       "      <td>1</td>\n",
       "      <td>156630-s2-p29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468779</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>Charting Asean's way forward Beyond the Asean ...</td>\n",
       "      <td>27</td>\n",
       "      <td>172108-s6-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468780</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>Asean 's way</td>\n",
       "      <td>3</td>\n",
       "      <td>172108-s6-p2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468781</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>Asean 's</td>\n",
       "      <td>2</td>\n",
       "      <td>172108-s6-p3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468782</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>the Asean Community 2015 goals</td>\n",
       "      <td>5</td>\n",
       "      <td>172108-s6-p4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468783</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>Asean leaders</td>\n",
       "      <td>2</td>\n",
       "      <td>172108-s6-p5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468784</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>the direction for a post-2015 vision for the g...</td>\n",
       "      <td>9</td>\n",
       "      <td>172108-s6-p6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468785</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>the direction</td>\n",
       "      <td>2</td>\n",
       "      <td>172108-s6-p7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468786</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>a post-2015 vision for the grouping</td>\n",
       "      <td>6</td>\n",
       "      <td>172108-s6-p8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468787</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>a post-2015 vision</td>\n",
       "      <td>3</td>\n",
       "      <td>172108-s6-p9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468788</th>\n",
       "      <td>172108-s6</td>\n",
       "      <td>the grouping</td>\n",
       "      <td>2</td>\n",
       "      <td>172108-s6-p10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469729</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469730</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>potentially</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469731</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>sinister</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469732</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>consequences</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p47</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469733</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p48</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469734</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>connecting</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469735</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469736</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>total</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469737</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>strangers</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p52</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469738</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>through</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469739</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>the</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p54</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469740</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>service,</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p55</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469741</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>when</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469742</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>secondary</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469743</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>school</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469744</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>student</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p59</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469745</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>Yan</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469746</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>starts</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469747</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>sending</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p62</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469748</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>sexy</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p63</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469749</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>pictures</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p64</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469750</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>of</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469751</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>herself</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p66</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469752</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469753</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p68</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469754</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>guy</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p69</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469755</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>she</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469756</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>does</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469757</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p72</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469758</th>\n",
       "      <td>152630-s14</td>\n",
       "      <td>know.</td>\n",
       "      <td>1</td>\n",
       "      <td>152630-s14-p73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id                                               text #words  \\\n",
       "468759   156630-s2                             daring one-armed lifts      3   \n",
       "468760   156630-s2  is no room for dramatic momentum amidst all th...     18   \n",
       "468761   156630-s2                                              There      1   \n",
       "468762   156630-s2                                                 is      1   \n",
       "468763   156630-s2                                                 no      1   \n",
       "468764   156630-s2                                               room      1   \n",
       "468765   156630-s2                                                for      1   \n",
       "468766   156630-s2                                           dramatic      1   \n",
       "468767   156630-s2                                           momentum      1   \n",
       "468768   156630-s2                                             amidst      1   \n",
       "468769   156630-s2                                                all      1   \n",
       "468770   156630-s2                                                the      1   \n",
       "468771   156630-s2                                           dizzying      1   \n",
       "468772   156630-s2                                        pirouettes,      1   \n",
       "468773   156630-s2                                        high-flying      1   \n",
       "468774   156630-s2                                              jumps      1   \n",
       "468775   156630-s2                                                and      1   \n",
       "468776   156630-s2                                             daring      1   \n",
       "468777   156630-s2                                          one-armed      1   \n",
       "468778   156630-s2                                             lifts.      1   \n",
       "468779   172108-s6  Charting Asean's way forward Beyond the Asean ...     27   \n",
       "468780   172108-s6                                       Asean 's way      3   \n",
       "468781   172108-s6                                           Asean 's      2   \n",
       "468782   172108-s6                     the Asean Community 2015 goals      5   \n",
       "468783   172108-s6                                      Asean leaders      2   \n",
       "468784   172108-s6  the direction for a post-2015 vision for the g...      9   \n",
       "468785   172108-s6                                      the direction      2   \n",
       "468786   172108-s6                a post-2015 vision for the grouping      6   \n",
       "468787   172108-s6                                 a post-2015 vision      3   \n",
       "468788   172108-s6                                       the grouping      2   \n",
       "...            ...                                                ...    ...   \n",
       "469729  152630-s14                                                the      1   \n",
       "469730  152630-s14                                        potentially      1   \n",
       "469731  152630-s14                                           sinister      1   \n",
       "469732  152630-s14                                       consequences      1   \n",
       "469733  152630-s14                                                 of      1   \n",
       "469734  152630-s14                                         connecting      1   \n",
       "469735  152630-s14                                               with      1   \n",
       "469736  152630-s14                                              total      1   \n",
       "469737  152630-s14                                          strangers      1   \n",
       "469738  152630-s14                                            through      1   \n",
       "469739  152630-s14                                                the      1   \n",
       "469740  152630-s14                                           service,      1   \n",
       "469741  152630-s14                                               when      1   \n",
       "469742  152630-s14                                          secondary      1   \n",
       "469743  152630-s14                                             school      1   \n",
       "469744  152630-s14                                            student      1   \n",
       "469745  152630-s14                                                Yan      1   \n",
       "469746  152630-s14                                             starts      1   \n",
       "469747  152630-s14                                            sending      1   \n",
       "469748  152630-s14                                               sexy      1   \n",
       "469749  152630-s14                                           pictures      1   \n",
       "469750  152630-s14                                                 of      1   \n",
       "469751  152630-s14                                            herself      1   \n",
       "469752  152630-s14                                                 to      1   \n",
       "469753  152630-s14                                                  a      1   \n",
       "469754  152630-s14                                                guy      1   \n",
       "469755  152630-s14                                                she      1   \n",
       "469756  152630-s14                                               does      1   \n",
       "469757  152630-s14                                                not      1   \n",
       "469758  152630-s14                                              know.      1   \n",
       "\n",
       "             phrase_id  score_correct is_sent snlp_sentiment_score  \\\n",
       "468759   156630-s2-p10            3.0    None                    3   \n",
       "468760   156630-s2-p11            3.0    None                    1   \n",
       "468761   156630-s2-p12            3.0    None                    2   \n",
       "468762   156630-s2-p13            3.0    None                    2   \n",
       "468763   156630-s2-p14            3.0    None                    1   \n",
       "468764   156630-s2-p15            3.0    None                    2   \n",
       "468765   156630-s2-p16            3.0    None                    2   \n",
       "468766   156630-s2-p17            3.0    None                    3   \n",
       "468767   156630-s2-p18            3.0    None                    2   \n",
       "468768   156630-s2-p19            3.0    None                    2   \n",
       "468769   156630-s2-p20            3.0    None                    2   \n",
       "468770   156630-s2-p21            3.0    None                    2   \n",
       "468771   156630-s2-p22            3.0    None                    2   \n",
       "468772   156630-s2-p23            3.0    None                    2   \n",
       "468773   156630-s2-p24            3.0    None                    2   \n",
       "468774   156630-s2-p25            3.0    None                    2   \n",
       "468775   156630-s2-p26            3.0    None                    2   \n",
       "468776   156630-s2-p27            3.0    None                    2   \n",
       "468777   156630-s2-p28            3.0    None                    2   \n",
       "468778   156630-s2-p29            3.0    None                    3   \n",
       "468779    172108-s6-p1            3.0    True                 None   \n",
       "468780    172108-s6-p2            3.0    None                    2   \n",
       "468781    172108-s6-p3            3.0    None                    2   \n",
       "468782    172108-s6-p4            3.0    None                    2   \n",
       "468783    172108-s6-p5            3.0    None                    2   \n",
       "468784    172108-s6-p6            3.0    None                    2   \n",
       "468785    172108-s6-p7            3.0    None                    2   \n",
       "468786    172108-s6-p8            3.0    None                    2   \n",
       "468787    172108-s6-p9            3.0    None                    2   \n",
       "468788   172108-s6-p10            3.0    None                    2   \n",
       "...                ...            ...     ...                  ...   \n",
       "469729  152630-s14-p44            3.0    None                    2   \n",
       "469730  152630-s14-p45            3.0    None                    2   \n",
       "469731  152630-s14-p46            3.0    None                    1   \n",
       "469732  152630-s14-p47            3.0    None                    2   \n",
       "469733  152630-s14-p48            3.0    None                    2   \n",
       "469734  152630-s14-p49            3.0    None                    2   \n",
       "469735  152630-s14-p50            3.0    None                    2   \n",
       "469736  152630-s14-p51            3.0    None                    2   \n",
       "469737  152630-s14-p52            3.0    None                    2   \n",
       "469738  152630-s14-p53            3.0    None                    2   \n",
       "469739  152630-s14-p54            3.0    None                    2   \n",
       "469740  152630-s14-p55            3.0    None                    2   \n",
       "469741  152630-s14-p56            3.0    None                    2   \n",
       "469742  152630-s14-p57            3.0    None                    1   \n",
       "469743  152630-s14-p58            3.0    None                    2   \n",
       "469744  152630-s14-p59            3.0    None                    2   \n",
       "469745  152630-s14-p60            3.0    None                    2   \n",
       "469746  152630-s14-p61            3.0    None                    2   \n",
       "469747  152630-s14-p62            3.0    None                    2   \n",
       "469748  152630-s14-p63            3.0    None                    4   \n",
       "469749  152630-s14-p64            3.0    None                    2   \n",
       "469750  152630-s14-p65            3.0    None                    2   \n",
       "469751  152630-s14-p66            3.0    None                    2   \n",
       "469752  152630-s14-p67            3.0    None                    2   \n",
       "469753  152630-s14-p68            3.0    None                    2   \n",
       "469754  152630-s14-p69            3.0    None                    2   \n",
       "469755  152630-s14-p70            3.0    None                    2   \n",
       "469756  152630-s14-p71            3.0    None                    2   \n",
       "469757  152630-s14-p72            3.0    None                    1   \n",
       "469758  152630-s14-p73            3.0    None                    2   \n",
       "\n",
       "       sentiment_score  \n",
       "468759               3  \n",
       "468760               1  \n",
       "468761               2  \n",
       "468762               2  \n",
       "468763               1  \n",
       "468764               2  \n",
       "468765               2  \n",
       "468766               3  \n",
       "468767               2  \n",
       "468768               2  \n",
       "468769               2  \n",
       "468770               2  \n",
       "468771               2  \n",
       "468772               2  \n",
       "468773               2  \n",
       "468774               2  \n",
       "468775               2  \n",
       "468776               2  \n",
       "468777               2  \n",
       "468778               3  \n",
       "468779               4  \n",
       "468780               2  \n",
       "468781               2  \n",
       "468782               2  \n",
       "468783               2  \n",
       "468784               2  \n",
       "468785               2  \n",
       "468786               2  \n",
       "468787               2  \n",
       "468788               2  \n",
       "...                ...  \n",
       "469729               2  \n",
       "469730               2  \n",
       "469731               1  \n",
       "469732               2  \n",
       "469733               2  \n",
       "469734               2  \n",
       "469735               2  \n",
       "469736               2  \n",
       "469737               2  \n",
       "469738               2  \n",
       "469739               2  \n",
       "469740               2  \n",
       "469741               2  \n",
       "469742               1  \n",
       "469743               2  \n",
       "469744               2  \n",
       "469745               2  \n",
       "469746               2  \n",
       "469747               2  \n",
       "469748               4  \n",
       "469749               2  \n",
       "469750               2  \n",
       "469751               2  \n",
       "469752               2  \n",
       "469753               2  \n",
       "469754               2  \n",
       "469755               2  \n",
       "469756               2  \n",
       "469757               1  \n",
       "469758               2  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [x for x in data_clean.sentiment_score.index if data_clean.loc[x,'sentiment_score'] == 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_id                 7212\n",
      "text                        None\n",
      "#words                         1\n",
      "phrase_id               7212-p66\n",
      "score_correct                  2\n",
      "is_sent                     None\n",
      "snlp_sentiment_score        None\n",
      "sentiment_score             None\n",
      "Name: 266237, dtype: object\n"
     ]
    }
   ],
   "source": [
    "c_ = data_clean.loc[c[0],]\n",
    "print(c_)\n",
    "data_clean = data_clean.drop(data_clean.index[c[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "      <td>4</td>\n",
       "      <td>0-p2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Canberra 's</td>\n",
       "      <td>2</td>\n",
       "      <td>0-p3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers arriving by boat</td>\n",
       "      <td>4</td>\n",
       "      <td>0-p4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>asylum-seekers</td>\n",
       "      <td>1</td>\n",
       "      <td>0-p5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text #words  \\\n",
       "0           0  Under Canberra's immigration policy, asylum-se...     28   \n",
       "1           0                     Canberra 's immigration policy      4   \n",
       "2           0                                        Canberra 's      2   \n",
       "3           0                    asylum-seekers arriving by boat      4   \n",
       "4           0                                     asylum-seekers      1   \n",
       "\n",
       "  phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
       "0      0-p1            2.0    True                 None               2  \n",
       "1      0-p2            2.0    None                    2               2  \n",
       "2      0-p3            2.0    None                    2               2  \n",
       "3      0-p4            2.0    None                    2               2  \n",
       "4      0-p5            2.0    None                    2               2  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_csv(\"110520_cleaned_sentences_phrases.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-b51e59729512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata_clean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata_clean_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-b51e59729512>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata_clean_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdata_clean_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_clean_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "data_clean = data_clean.sort_values('phrase_id')\n",
    "data_clean__ = pd.DataFrame()\n",
    "\n",
    "for idx, grp in data_clean.groupby('sentence_id'):\n",
    "    data_clean__ = data_clean__.append(grp, ignore_index=True)\n",
    "    data_clean__['sentence_id'] = idx\n",
    "    data_clean__ = data_clean__.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "\n",
    "data_clean_ = data_clean__[['sentiment_score','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>their asylum application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>arriving by boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>are transferred to the centres for processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>transferred to the centres for processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>is successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>are permanently resettled outside Australia .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>resettled outside Australia .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>policy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>asylum-seekers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>arriving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>transferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>tyrants or schemers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>Five large high-volume, low-speed fans will co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>high-volume,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>low-speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>without</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>messing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>Five large high-volume , low-speed fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>hair,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>saving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>energy..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>saving energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>will cool diners without messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>cool diners without messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>Market players say it could take months for lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment_score                                               text\n",
       "0                2  Under Canberra's immigration policy, asylum-se...\n",
       "1                2                           their asylum application\n",
       "2                2                                               they\n",
       "3                2                                          Australia\n",
       "4                2                                   arriving by boat\n",
       "5                2      are transferred to the centres for processing\n",
       "6                2          transferred to the centres for processing\n",
       "7                3                                      is successful\n",
       "8                2      are permanently resettled outside Australia .\n",
       "9                2                      resettled outside Australia .\n",
       "10               2                                              Under\n",
       "11               2                     Canberra 's immigration policy\n",
       "12               2                                         Canberra's\n",
       "13               2                                        immigration\n",
       "14               2                                            policy,\n",
       "15               2                                     asylum-seekers\n",
       "16               2                                           arriving\n",
       "17               2                                                 by\n",
       "18               2                                               boat\n",
       "19               2                                                are\n",
       "20               2                                        transferred\n",
       "21               2                                                 to\n",
       "22               2                                        Canberra 's\n",
       "23               2                                                the\n",
       "24               2                                            centres\n",
       "25               2                                                for\n",
       "26               2                                         processing\n",
       "27               2                                                and\n",
       "28               2                                                 if\n",
       "29               2                                              their\n",
       "..             ...                                                ...\n",
       "70               2                                tyrants or schemers\n",
       "71               2                                                 he\n",
       "72                                                                   \n",
       "73               3  Five large high-volume, low-speed fans will co...\n",
       "74               2                                              large\n",
       "75               2                                       high-volume,\n",
       "76               2                                          low-speed\n",
       "77               3                                               fans\n",
       "78               2                                               will\n",
       "79               3                                               cool\n",
       "80               2                                             diners\n",
       "81               2                                            without\n",
       "82               1                                            messing\n",
       "83               2                                                 up\n",
       "84               1            Five large high-volume , low-speed fans\n",
       "85               2                                              their\n",
       "86               2                                              hair,\n",
       "87               2                                              while\n",
       "88               2                                               also\n",
       "89               3                                             saving\n",
       "90               2                                           energy..\n",
       "91               2                                             diners\n",
       "92               2                                         their hair\n",
       "93               2                                      saving energy\n",
       "94               2     will cool diners without messing up their hair\n",
       "95               2          cool diners without messing up their hair\n",
       "96               2                              messing up their hair\n",
       "97               2                                               Five\n",
       "98                                                                   \n",
       "99               1  Market players say it could take months for lo...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return ' '\n",
    "    \n",
    "data_clean_['sentiment_score'] = data_clean_['sentiment_score'].apply(lambda x: get_int(x))\n",
    "data_clean_ = data_clean_.astype(object).replace(np.nan, ' ')\n",
    "data_clean_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'110520_training_for_ptb.txt', data_clean_.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment_score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>13241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text\n",
       "sentiment_score        \n",
       "0                  2132\n",
       "1                 32806\n",
       "2                400181\n",
       "3                 30339\n",
       "4                  4300\n",
       "                  13241"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [x for x in data_clean.index if data_clean.loc[x,'phrase_id'].endswith('-p1')]\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13240\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "      <td>28</td>\n",
       "      <td>0-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baritone roles are usually villainous charact...</td>\n",
       "      <td>14</td>\n",
       "      <td>1-p1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>10</td>\n",
       "      <td>The male suspect's father later loaded the bod...</td>\n",
       "      <td>34</td>\n",
       "      <td>10-p1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>100</td>\n",
       "      <td>NEW YORK (AFP) - Dressed as Santas and sexy sn...</td>\n",
       "      <td>34</td>\n",
       "      <td>100-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37117</th>\n",
       "      <td>1000</td>\n",
       "      <td>The delegates from Angola, Ghana, Mauritius, N...</td>\n",
       "      <td>30</td>\n",
       "      <td>1000-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id                                               text #words  \\\n",
       "0               0  Under Canberra's immigration policy, asylum-se...     28   \n",
       "46              1  \"Baritone roles are usually villainous charact...     14   \n",
       "312            10  The male suspect's father later loaded the bod...     34   \n",
       "3820          100  NEW YORK (AFP) - Dressed as Santas and sexy sn...     34   \n",
       "37117        1000  The delegates from Angola, Ghana, Mauritius, N...     30   \n",
       "\n",
       "      phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
       "0          0-p1            2.0    True                 None               2  \n",
       "46         1-p1            1.0    True                 None               1  \n",
       "312       10-p1            1.0    True                 None               1  \n",
       "3820     100-p1            3.0    True                 None               3  \n",
       "37117   1000-p1            3.0    True                 None               3  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_nd = data_clean.loc[idx]\n",
    "print(len(data_clean_nd.index))\n",
    "data_clean_nd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_score\n",
       "0.0    1730\n",
       "1.0    2260\n",
       "2.0    3651\n",
       "3.0    3398\n",
       "4.0    2201\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_nd.groupby(['sentiment_score'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_nd_2 = data_clean_nd[data_clean_nd['sentiment_score']==2].sample(2500, random_state=42)\n",
    "data_clean_nd_3 = data_clean_nd[data_clean_nd['sentiment_score']==3].sample(2500, random_state=42)\n",
    "data_clean_nd_ = data_clean_nd[data_clean_nd['sentiment_score']==0]\n",
    "data_clean_nd_ = data_clean_nd_.append([data_clean_nd_2,data_clean_nd_3,data_clean_nd[data_clean_nd['sentiment_score']==4],\\\n",
    "                                       data_clean_nd[data_clean_nd['sentiment_score']==1]], ignore_index=True)\n",
    "newdata = data_clean_nd_.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_score\n",
       "0.0    1730\n",
       "1.0    2260\n",
       "2.0    2500\n",
       "3.0    2500\n",
       "4.0    2201\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean_nd_.groupby(['sentiment_score'])['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11191"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>#words</th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>score_correct</th>\n",
       "      <th>is_sent</th>\n",
       "      <th>snlp_sentiment_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189617-s9</td>\n",
       "      <td>Pregnancy, labour and afterwards are experienc...</td>\n",
       "      <td>15</td>\n",
       "      <td>189617-s9-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3208</td>\n",
       "      <td>She says: \"I think this has been a \"new normal...</td>\n",
       "      <td>20</td>\n",
       "      <td>3208-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3376</td>\n",
       "      <td>Engineers claim the robot's artificial intelli...</td>\n",
       "      <td>20</td>\n",
       "      <td>3376-p1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4163</td>\n",
       "      <td>BDO interviewed 67 finance chiefs from clubs i...</td>\n",
       "      <td>22</td>\n",
       "      <td>4163-p1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156615-s27</td>\n",
       "      <td>Giving herself to the possibility of happy acc...</td>\n",
       "      <td>16</td>\n",
       "      <td>156615-s27-p1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                               text #words  \\\n",
       "0   189617-s9  Pregnancy, labour and afterwards are experienc...     15   \n",
       "1        3208  She says: \"I think this has been a \"new normal...     20   \n",
       "2        3376  Engineers claim the robot's artificial intelli...     20   \n",
       "3        4163  BDO interviewed 67 finance chiefs from clubs i...     22   \n",
       "4  156615-s27  Giving herself to the possibility of happy acc...     16   \n",
       "\n",
       "       phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
       "0   189617-s9-p1            3.0    True                 None               4  \n",
       "1        3208-p1            2.0    True                 None               2  \n",
       "2        3376-p1            2.0    True                 None               2  \n",
       "3        4163-p1            1.0    True                 None               1  \n",
       "4  156615-s27-p1            3.0    True                 None               3  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidl = newdata['sentence_id'].tolist()\n",
    "data_nd = data_clean[data_clean['sentence_id'].isin(sidl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11191\n",
      "0    sentence_id                                               text #words  \\\n",
      "0            0  Under Canberra's immigration policy, asylum-se...     28   \n",
      "9            0                           their asylum application      3   \n",
      "10           0                                               they      1   \n",
      "11           0                                          Australia      1   \n",
      "12           0                                   arriving by boat      3   \n",
      "13           0      are transferred to the centres for processing      7   \n",
      "14           0          transferred to the centres for processing      6   \n",
      "15           0                                      is successful      2   \n",
      "16           0      are permanently resettled outside Australia .      6   \n",
      "17           0                      resettled outside Australia .      4   \n",
      "18           0                                              Under      1   \n",
      "1            0                     Canberra 's immigration policy      4   \n",
      "19           0                                         Canberra's      1   \n",
      "20           0                                        immigration      1   \n",
      "21           0                                            policy,      1   \n",
      "22           0                                     asylum-seekers      1   \n",
      "23           0                                           arriving      1   \n",
      "24           0                                                 by      1   \n",
      "25           0                                               boat      1   \n",
      "26           0                                                are      1   \n",
      "27           0                                        transferred      1   \n",
      "28           0                                                 to      1   \n",
      "2            0                                        Canberra 's      2   \n",
      "29           0                                                the      1   \n",
      "30           0                                            centres      1   \n",
      "31           0                                                for      1   \n",
      "32           0                                         processing      1   \n",
      "33           0                                                and      1   \n",
      "34           0                                                 if      1   \n",
      "35           0                                              their      1   \n",
      "36           0                                             asylum      1   \n",
      "37           0                                        application      1   \n",
      "38           0                                                 is      1   \n",
      "3            0                    asylum-seekers arriving by boat      4   \n",
      "39           0                                         successful      1   \n",
      "40           0                                               they      1   \n",
      "41           0                                                are      1   \n",
      "42           0                                        permanently      1   \n",
      "43           0                                          resettled      1   \n",
      "44           0                                            outside      1   \n",
      "45           0                                        Australia..      1   \n",
      "4            0                                     asylum-seekers      1   \n",
      "5            0                                               boat      1   \n",
      "6            0                         the centres for processing      4   \n",
      "7            0                                        the centres      2   \n",
      "8            0                                         processing      1   \n",
      "\n",
      "   phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "0       0-p1            2.0    True                 None               2  \n",
      "9      0-p10            2.0    None                    2               2  \n",
      "10     0-p11            2.0    None                    2               2  \n",
      "11     0-p12            2.0    None                    2               2  \n",
      "12     0-p13            2.0    None                    2               2  \n",
      "13     0-p14            2.0    None                    2               2  \n",
      "14     0-p15            2.0    None                    2               2  \n",
      "15     0-p16            2.0    None                    3               3  \n",
      "16     0-p17            2.0    None                    2               2  \n",
      "17     0-p18            2.0    None                    2               2  \n",
      "18     0-p19            2.0    None                    2               2  \n",
      "1       0-p2            2.0    None                    2               2  \n",
      "19     0-p20            2.0    None                    2               2  \n",
      "20     0-p21            2.0    None                    2               2  \n",
      "21     0-p22            2.0    None                    2               2  \n",
      "22     0-p23            2.0    None                    2               2  \n",
      "23     0-p24            2.0    None                    2               2  \n",
      "24     0-p25            2.0    None                    2               2  \n",
      "25     0-p26            2.0    None                    2               2  \n",
      "26     0-p27            2.0    None                    2               2  \n",
      "27     0-p28            2.0    None                    2               2  \n",
      "28     0-p29            2.0    None                    2               2  \n",
      "2       0-p3            2.0    None                    2               2  \n",
      "29     0-p30            2.0    None                    2               2  \n",
      "30     0-p31            2.0    None                    2               2  \n",
      "31     0-p32            2.0    None                    2               2  \n",
      "32     0-p33            2.0    None                    2               2  \n",
      "33     0-p34            2.0    None                    2               2  \n",
      "34     0-p35            2.0    None                    2               2  \n",
      "35     0-p36            2.0    None                    2               2  \n",
      "36     0-p37            2.0    None                    2               2  \n",
      "37     0-p38            2.0    None                    2               2  \n",
      "38     0-p39            2.0    None                    2               2  \n",
      "3       0-p4            2.0    None                    2               2  \n",
      "39     0-p40            2.0    None                    4               4  \n",
      "40     0-p41            2.0    None                    2               2  \n",
      "41     0-p42            2.0    None                    2               2  \n",
      "42     0-p43            2.0    None                    2               2  \n",
      "43     0-p44            2.0    None                    2               2  \n",
      "44     0-p45            2.0    None                    2               2  \n",
      "45     0-p46            2.0    None                    2               2  \n",
      "4       0-p5            2.0    None                    2               2  \n",
      "5       0-p6            2.0    None                    2               2  \n",
      "6       0-p7            2.0    None                    2               2  \n",
      "7       0-p8            2.0    None                    2               2  \n",
      "8       0-p9            2.0    None                    2               2  \n",
      "1    sentence_id                                               text #words  \\\n",
      "46           1  \"Baritone roles are usually villainous charact...     14   \n",
      "55           1  are usually villainous characters , such as mu...     17   \n",
      "56           1                                               says      1   \n",
      "57           1                                          \"Baritone      1   \n",
      "58           1                                              roles      1   \n",
      "59           1                                                are      1   \n",
      "60           1                                            usually      1   \n",
      "61           1                                         villainous      1   \n",
      "62           1                                        characters,      1   \n",
      "63           1                                               such      1   \n",
      "64           1                                                 as      1   \n",
      "47           1                                     Baritone roles      2   \n",
      "65           1                                         murderers,      1   \n",
      "66           1                                            tyrants      1   \n",
      "67           1                                                 or      1   \n",
      "68           1                                         schemers,\"      1   \n",
      "69           1                                                 he      1   \n",
      "70           1                                             says..      1   \n",
      "48           1  villainous characters , such as murderers , ty...     15   \n",
      "49           1                                         villainous      1   \n",
      "50           1                                         characters      1   \n",
      "51           1       murderers , tyrants or schemers , '' he says      9   \n",
      "52           1                                          murderers      1   \n",
      "53           1                                tyrants or schemers      3   \n",
      "54           1                                                 he      1   \n",
      "\n",
      "   phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "46      1-p1            1.0    True                 None               1  \n",
      "55     1-p10            1.0    None                    1               1  \n",
      "56     1-p11            1.0    None                    2               2  \n",
      "57     1-p12            1.0    None                    2               2  \n",
      "58     1-p13            1.0    None                    2               2  \n",
      "59     1-p14            1.0    None                    2               2  \n",
      "60     1-p15            1.0    None                    2               2  \n",
      "61     1-p16            1.0    None                    1               1  \n",
      "62     1-p17            1.0    None                    2               2  \n",
      "63     1-p18            1.0    None                    2               2  \n",
      "64     1-p19            1.0    None                    2               2  \n",
      "47      1-p2            1.0    None                    2               2  \n",
      "65     1-p20            1.0    None                    2               2  \n",
      "66     1-p21            1.0    None                    2               2  \n",
      "67     1-p22            1.0    None                    2               2  \n",
      "68     1-p23            1.0    None                    2               2  \n",
      "69     1-p24            1.0    None                    2               2  \n",
      "70     1-p25            1.0    None                    2               2  \n",
      "48      1-p3            1.0    None                    1               1  \n",
      "49      1-p4            1.0    None                    1               1  \n",
      "50      1-p5            1.0    None                    2               2  \n",
      "51      1-p6            1.0    None                    1               1  \n",
      "52      1-p7            1.0    None                    2               2  \n",
      "53      1-p8            1.0    None                    2               2  \n",
      "54      1-p9            1.0    None                    2               2  \n",
      "2    sentence_id                                               text #words  \\\n",
      "71           2  Five large high-volume, low-speed fans will co...     17   \n",
      "80           2                                              large      1   \n",
      "81           2                                       high-volume,      1   \n",
      "82           2                                          low-speed      1   \n",
      "83           2                                               fans      1   \n",
      "84           2                                               will      1   \n",
      "85           2                                               cool      1   \n",
      "86           2                                             diners      1   \n",
      "87           2                                            without      1   \n",
      "88           2                                            messing      1   \n",
      "89           2                                                 up      1   \n",
      "72           2            Five large high-volume , low-speed fans      6   \n",
      "90           2                                              their      1   \n",
      "91           2                                              hair,      1   \n",
      "92           2                                              while      1   \n",
      "93           2                                               also      1   \n",
      "94           2                                             saving      1   \n",
      "95           2                                           energy..      1   \n",
      "73           2                                             diners      1   \n",
      "74           2                                         their hair      2   \n",
      "75           2                                      saving energy      2   \n",
      "76           2     will cool diners without messing up their hair      8   \n",
      "77           2          cool diners without messing up their hair      7   \n",
      "78           2                              messing up their hair      4   \n",
      "79           2                                               Five      1   \n",
      "\n",
      "   phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "71      2-p1            3.0    True                 None               3  \n",
      "80     2-p10            3.0    None                    2               2  \n",
      "81     2-p11            3.0    None                    2               2  \n",
      "82     2-p12            3.0    None                    2               2  \n",
      "83     2-p13            3.0    None                    3               3  \n",
      "84     2-p14            3.0    None                    2               2  \n",
      "85     2-p15            3.0    None                    3               3  \n",
      "86     2-p16            3.0    None                    2               2  \n",
      "87     2-p17            3.0    None                    2               2  \n",
      "88     2-p18            3.0    None                    1               1  \n",
      "89     2-p19            3.0    None                    2               2  \n",
      "72      2-p2            3.0    None                    1               1  \n",
      "90     2-p20            3.0    None                    2               2  \n",
      "91     2-p21            3.0    None                    2               2  \n",
      "92     2-p22            3.0    None                    2               2  \n",
      "93     2-p23            3.0    None                    2               2  \n",
      "94     2-p24            3.0    None                    3               3  \n",
      "95     2-p25            3.0    None                    2               2  \n",
      "73      2-p3            3.0    None                    2               2  \n",
      "74      2-p4            3.0    None                    2               2  \n",
      "75      2-p5            3.0    None                    2               2  \n",
      "76      2-p6            3.0    None                    2               2  \n",
      "77      2-p7            3.0    None                    2               2  \n",
      "78      2-p8            3.0    None                    2               2  \n",
      "79      2-p9            3.0    None                    2               2  \n",
      "3     sentence_id                                               text #words  \\\n",
      "96            3  Market players say it could take months for lo...     25   \n",
      "105           3                                  its peculiarities      2   \n",
      "106           3  say it could take months for long-term investo...     25   \n",
      "107           3  could take months for long-term investors to e...     12   \n",
      "108           3  take months for long-term investors to eventua...     11   \n",
      "109           3           to eventually trickle into the programme      6   \n",
      "110           3              eventually trickle into the programme      5   \n",
      "111           3         devise ways to cope with its peculiarities      7   \n",
      "112           3                     to cope with its peculiarities      5   \n",
      "113           3                        cope with its peculiarities      4   \n",
      "114           3                                             Market      1   \n",
      "97            3                                     Market players      2   \n",
      "115           3                                            players      1   \n",
      "116           3                                                say      1   \n",
      "117           3                                                 it      1   \n",
      "118           3                                              could      1   \n",
      "119           3                                               take      1   \n",
      "120           3                                             months      1   \n",
      "121           3                                                for      1   \n",
      "122           3                                          long-term      1   \n",
      "123           3                                          investors      1   \n",
      "124           3                                                 to      1   \n",
      "98            3                                                 it      1   \n",
      "125           3                                         eventually      1   \n",
      "126           3                                            trickle      1   \n",
      "127           3                                               into      1   \n",
      "128           3                                                the      1   \n",
      "129           3                                         programme,      1   \n",
      "130           3                                                 as      1   \n",
      "131           3                                               they      1   \n",
      "132           3                                             devise      1   \n",
      "133           3                                               ways      1   \n",
      "134           3                                                 to      1   \n",
      "99            3                     months for long-term investors      4   \n",
      "135           3                                               cope      1   \n",
      "136           3                                               with      1   \n",
      "137           3                                                its      1   \n",
      "138           3                                    peculiarities..      1   \n",
      "100           3                                             months      1   \n",
      "101           3                                long-term investors      2   \n",
      "102           3                                      the programme      2   \n",
      "103           3                                               they      1   \n",
      "104           3                                               ways      1   \n",
      "\n",
      "    phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "96       3-p1            1.0    True                 None               1  \n",
      "105     3-p10            1.0    None                    2               2  \n",
      "106     3-p11            1.0    None                    2               2  \n",
      "107     3-p12            1.0    None                    2               2  \n",
      "108     3-p13            1.0    None                    2               2  \n",
      "109     3-p14            1.0    None                    2               2  \n",
      "110     3-p15            1.0    None                    2               2  \n",
      "111     3-p16            1.0    None                    2               2  \n",
      "112     3-p17            1.0    None                    2               2  \n",
      "113     3-p18            1.0    None                    2               2  \n",
      "114     3-p19            1.0    None                    2               2  \n",
      "97       3-p2            1.0    None                    2               2  \n",
      "115     3-p20            1.0    None                    2               2  \n",
      "116     3-p21            1.0    None                    2               2  \n",
      "117     3-p22            1.0    None                    2               2  \n",
      "118     3-p23            1.0    None                    2               2  \n",
      "119     3-p24            1.0    None                    2               2  \n",
      "120     3-p25            1.0    None                    2               2  \n",
      "121     3-p26            1.0    None                    2               2  \n",
      "122     3-p27            1.0    None                    2               2  \n",
      "123     3-p28            1.0    None                    2               2  \n",
      "124     3-p29            1.0    None                    2               2  \n",
      "98       3-p3            1.0    None                    2               2  \n",
      "125     3-p30            1.0    None                    2               2  \n",
      "126     3-p31            1.0    None                    2               2  \n",
      "127     3-p32            1.0    None                    2               2  \n",
      "128     3-p33            1.0    None                    2               2  \n",
      "129     3-p34            1.0    None                    2               2  \n",
      "130     3-p35            1.0    None                    2               2  \n",
      "131     3-p36            1.0    None                    2               2  \n",
      "132     3-p37            1.0    None                    2               2  \n",
      "133     3-p38            1.0    None                    2               2  \n",
      "134     3-p39            1.0    None                    2               2  \n",
      "99       3-p4            1.0    None                    2               2  \n",
      "135     3-p40            1.0    None                    2               2  \n",
      "136     3-p41            1.0    None                    2               2  \n",
      "137     3-p42            1.0    None                    2               2  \n",
      "138     3-p43            1.0    None                    2               2  \n",
      "100      3-p5            1.0    None                    2               2  \n",
      "101      3-p6            1.0    None                    2               2  \n",
      "102      3-p7            1.0    None                    2               2  \n",
      "103      3-p8            1.0    None                    2               2  \n",
      "104      3-p9            1.0    None                    2               2  \n",
      "4     sentence_id                                               text #words  \\\n",
      "139           4  But if we had to keep relying on our past rese...     21   \n",
      "148           4                       relying on our past reserves      5   \n",
      "149           4  think after a while we would have exhausted th...     10   \n",
      "150           4                          would have exhausted them      4   \n",
      "151           4                                have exhausted them      3   \n",
      "152           4                                     exhausted them      2   \n",
      "153           4                                                But      1   \n",
      "154           4                                                 if      1   \n",
      "155           4                                                 we      1   \n",
      "156           4                                                had      1   \n",
      "157           4                                                 to      1   \n",
      "140           4                                                 we      1   \n",
      "158           4                                               keep      1   \n",
      "159           4                                            relying      1   \n",
      "160           4                                                 on      1   \n",
      "161           4                                                our      1   \n",
      "162           4                                               past      1   \n",
      "163           4                                          reserves,      1   \n",
      "164           4                                                  I      1   \n",
      "165           4                                              think      1   \n",
      "166           4                                              after      1   \n",
      "167           4                                                  a      1   \n",
      "141           4                                  our past reserves      3   \n",
      "168           4                                              while      1   \n",
      "169           4                                                 we      1   \n",
      "170           4                                              would      1   \n",
      "171           4                                               have      1   \n",
      "172           4                                          exhausted      1   \n",
      "173           4                                             them..      1   \n",
      "142           4                                                  I      1   \n",
      "143           4                                                 we      1   \n",
      "144           4                                               them      1   \n",
      "145           4           had to keep relying on our past reserves      8   \n",
      "146           4               to keep relying on our past reserves      7   \n",
      "147           4                  keep relying on our past reserves      6   \n",
      "\n",
      "    phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "139      4-p1            3.0    True                 None               3  \n",
      "148     4-p10            3.0    None                    2               2  \n",
      "149     4-p11            3.0    None                    2               2  \n",
      "150     4-p12            3.0    None                    2               2  \n",
      "151     4-p13            3.0    None                    2               2  \n",
      "152     4-p14            3.0    None                    2               2  \n",
      "153     4-p15            3.0    None                    2               2  \n",
      "154     4-p16            3.0    None                    2               2  \n",
      "155     4-p17            3.0    None                    2               2  \n",
      "156     4-p18            3.0    None                    2               2  \n",
      "157     4-p19            3.0    None                    2               2  \n",
      "140      4-p2            3.0    None                    2               2  \n",
      "158     4-p20            3.0    None                    2               2  \n",
      "159     4-p21            3.0    None                    2               2  \n",
      "160     4-p22            3.0    None                    2               2  \n",
      "161     4-p23            3.0    None                    2               2  \n",
      "162     4-p24            3.0    None                    2               2  \n",
      "163     4-p25            3.0    None                    2               2  \n",
      "164     4-p26            3.0    None                    2               2  \n",
      "165     4-p27            3.0    None                    2               2  \n",
      "166     4-p28            3.0    None                    2               2  \n",
      "167     4-p29            3.0    None                    2               2  \n",
      "141      4-p3            3.0    None                    2               2  \n",
      "168     4-p30            3.0    None                    2               2  \n",
      "169     4-p31            3.0    None                    2               2  \n",
      "170     4-p32            3.0    None                    2               2  \n",
      "171     4-p33            3.0    None                    2               2  \n",
      "172     4-p34            3.0    None                    1               1  \n",
      "173     4-p35            3.0    None                    2               2  \n",
      "142      4-p4            3.0    None                    2               2  \n",
      "143      4-p5            3.0    None                    2               2  \n",
      "144      4-p6            3.0    None                    2               2  \n",
      "145      4-p7            3.0    None                    2               2  \n",
      "146      4-p8            3.0    None                    2               2  \n",
      "147      4-p9            3.0    None                    2               2  \n",
      "5     sentence_id                                               text #words  \\\n",
      "174           5  When that happens, I know there is a book ther...     15   \n",
      "183           5                                    is a book there      4   \n",
      "184           5                                    ca n't force it      4   \n",
      "185           5                                           force it      2   \n",
      "186           5                                               When      1   \n",
      "187           5                                               that      1   \n",
      "188           5                                           happens,      1   \n",
      "189           5                                                  I      1   \n",
      "190           5                                               know      1   \n",
      "191           5                                              there      1   \n",
      "192           5                                                 is      1   \n",
      "175           5                                               that      1   \n",
      "193           5                                                  a      1   \n",
      "194           5                                               book      1   \n",
      "195           5                                             there,      1   \n",
      "196           5                                                but      1   \n",
      "197           5                                                  I      1   \n",
      "198           5                                              can't      1   \n",
      "199           5                                              force      1   \n",
      "200           5                                              it.\".      1   \n",
      "176           5                                                  I      1   \n",
      "177           5                                              there      1   \n",
      "178           5                                             a book      2   \n",
      "179           5                                                  I      1   \n",
      "180           5                                                 it      1   \n",
      "181           5                                            happens      1   \n",
      "182           5  know there is a book there , but I ca n't forc...     15   \n",
      "\n",
      "    phrase_id  score_correct is_sent snlp_sentiment_score sentiment_score  \n",
      "174      5-p1            2.0    True                 None               2  \n",
      "183     5-p10            2.0    None                    2               2  \n",
      "184     5-p11            2.0    None                    2               2  \n",
      "185     5-p12            2.0    None                    2               2  \n",
      "186     5-p13            2.0    None                    2               2  \n",
      "187     5-p14            2.0    None                    2               2  \n",
      "188     5-p15            2.0    None                    2               2  \n",
      "189     5-p16            2.0    None                    2               2  \n",
      "190     5-p17            2.0    None                    2               2  \n",
      "191     5-p18            2.0    None                    2               2  \n",
      "192     5-p19            2.0    None                    2               2  \n",
      "175      5-p2            2.0    None                    2               2  \n",
      "193     5-p20            2.0    None                    2               2  \n",
      "194     5-p21            2.0    None                    2               2  \n",
      "195     5-p22            2.0    None                    2               2  \n",
      "196     5-p23            2.0    None                    2               2  \n",
      "197     5-p24            2.0    None                    2               2  \n",
      "198     5-p25            2.0    None                    2               2  \n",
      "199     5-p26            2.0    None                    2               2  \n",
      "200     5-p27            2.0    None                    2               2  \n",
      "176      5-p3            2.0    None                    2               2  \n",
      "177      5-p4            2.0    None                    2               2  \n",
      "178      5-p5            2.0    None                    2               2  \n",
      "179      5-p6            2.0    None                    2               2  \n",
      "180      5-p7            2.0    None                    2               2  \n",
      "181      5-p8            2.0    None                    2               2  \n",
      "182      5-p9            2.0    None                    1               1  \n"
     ]
    }
   ],
   "source": [
    "idx2 = [x for x in data_nd.index if data_nd.loc[x,'phrase_id'].endswith('-p1')]\n",
    "print(len(idx2))\n",
    "\n",
    "count=0\n",
    "for i,grp in data_nd.groupby('sentence_id'):\n",
    "    print(i,grp)\n",
    "    count += 1\n",
    "    if count > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nd.to_csv(\"110520_distbn2_training_data.csv\",index=None)\n",
    "data_nd = data_nd.sort_values('phrase_id')\n",
    "data_clean__ = pd.DataFrame()\n",
    "\n",
    "for idx, grp in data_nd.groupby('sentence_id'):\n",
    "    data_clean__ = data_clean__.append(grp, ignore_index=True)\n",
    "    data_clean__['sentence_id'] = idx\n",
    "    data_clean__ = data_clean__.append(pd.Series(), ignore_index=True)\n",
    "\n",
    "\n",
    "data_clean_ = data_clean__[['sentiment_score','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NAS/home01/toshal/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Canberra's immigration policy, asylum-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>their asylum application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>arriving by boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>are transferred to the centres for processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>transferred to the centres for processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>is successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>are permanently resettled outside Australia .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>resettled outside Australia .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra 's immigration policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>policy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>asylum-seekers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>arriving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>transferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>Canberra 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>tyrants or schemers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>Five large high-volume, low-speed fans will co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>high-volume,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>low-speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>without</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>messing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>Five large high-volume , low-speed fans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2</td>\n",
       "      <td>hair,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2</td>\n",
       "      <td>while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>saving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2</td>\n",
       "      <td>energy..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>diners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>saving energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2</td>\n",
       "      <td>will cool diners without messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>cool diners without messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>messing up their hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>Market players say it could take months for lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment_score                                               text\n",
       "0                2  Under Canberra's immigration policy, asylum-se...\n",
       "1                2                           their asylum application\n",
       "2                2                                               they\n",
       "3                2                                          Australia\n",
       "4                2                                   arriving by boat\n",
       "5                2      are transferred to the centres for processing\n",
       "6                2          transferred to the centres for processing\n",
       "7                3                                      is successful\n",
       "8                2      are permanently resettled outside Australia .\n",
       "9                2                      resettled outside Australia .\n",
       "10               2                                              Under\n",
       "11               2                     Canberra 's immigration policy\n",
       "12               2                                         Canberra's\n",
       "13               2                                        immigration\n",
       "14               2                                            policy,\n",
       "15               2                                     asylum-seekers\n",
       "16               2                                           arriving\n",
       "17               2                                                 by\n",
       "18               2                                               boat\n",
       "19               2                                                are\n",
       "20               2                                        transferred\n",
       "21               2                                                 to\n",
       "22               2                                        Canberra 's\n",
       "23               2                                                the\n",
       "24               2                                            centres\n",
       "25               2                                                for\n",
       "26               2                                         processing\n",
       "27               2                                                and\n",
       "28               2                                                 if\n",
       "29               2                                              their\n",
       "..             ...                                                ...\n",
       "70               2                                tyrants or schemers\n",
       "71               2                                                 he\n",
       "72                                                                   \n",
       "73               3  Five large high-volume, low-speed fans will co...\n",
       "74               2                                              large\n",
       "75               2                                       high-volume,\n",
       "76               2                                          low-speed\n",
       "77               3                                               fans\n",
       "78               2                                               will\n",
       "79               3                                               cool\n",
       "80               2                                             diners\n",
       "81               2                                            without\n",
       "82               1                                            messing\n",
       "83               2                                                 up\n",
       "84               1            Five large high-volume , low-speed fans\n",
       "85               2                                              their\n",
       "86               2                                              hair,\n",
       "87               2                                              while\n",
       "88               2                                               also\n",
       "89               3                                             saving\n",
       "90               2                                           energy..\n",
       "91               2                                             diners\n",
       "92               2                                         their hair\n",
       "93               2                                      saving energy\n",
       "94               2     will cool diners without messing up their hair\n",
       "95               2          cool diners without messing up their hair\n",
       "96               2                              messing up their hair\n",
       "97               2                                               Five\n",
       "98                                                                   \n",
       "99               1  Market players say it could take months for lo...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return ' '\n",
    "    \n",
    "data_clean_['sentiment_score'] = data_clean_['sentiment_score'].apply(lambda x: get_int(x))\n",
    "data_clean_ = data_clean_.astype(object).replace(np.nan, ' ')\n",
    "data_clean_.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(r'110520_distbn2_training_for_ptb.txt', data_clean_.values, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
